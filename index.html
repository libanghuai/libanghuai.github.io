<!DOCTYPE html>
<html>
 <head>
<meta name="viewport" content="width=device-width,initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
  <link rel="stylesheet" type="text/css" id="u0" href="https://zh.rakko.tools/tools/129/lib/tinymce/skins/ui/oxide/content.min.css" />
  <link rel="stylesheet" type="text/css" id="u1" href="https://zh.rakko.tools/tools/129/lib/tinymce/skins/content/default/content.min.css" />
 </head>
 <body id="tinymce" class="mce-content-body " data-id="content" contenteditable="true" spellcheck="false" data-new-gr-c-s-loaded="14.1097.0" data-new-gr-c-s-check-loaded="14.1097.0" data-gr-ext-installed="">
  <table style="border-collapse: collapse; width: 50%; height: 198px;text-align:center;margin:0 auto;" border="1">
   <tbody>
    <tr style="height: 22px;">
     <td style="width: 70%; height: 22px; text-align: center;border-color: transparent;"><p><h2>Banghuai Li</h2></p><p>I received an M.S. degree in the EECS from Peking University in 2018. I am currently a Staff R&amp;D Engineer at Momenta. Before that, I was a Researcher at Megvii. My research interests include 2D/3D vision, autonomous driving, and artificial intelligence. Now I serve as a  regular reviewer for CVPR/ICCV/ECCV/TIP etc. </p></br>
<a href = "https://scholar.google.com/citations?user=RNBZqacAAAAJ&hl=da"> [Google Scholar]</a>
<a href = ""> [CV]</a>
<a href = ""> [E-mail: libanghuai@gmail.com]</a>
</td>
     <td style="width: 30%; height: 22px;border-color: transparent;"><img src="https://github.com/libanghuai/libanghuai.github.io/blob/main/WechatIMG2488.jpeg?raw=true" width=100% height=auto></td>
    </tr>
   </tbody>

  </table>
<table style="border-collapse: collapse; width: 60%; height: 198px;text-align:center;margin:0 auto;" border="0">
   <body>
<tr>
     <td style="width: 100%; text-align: left;border-color: transparent;"><p><h2>News</h2></p>
<hr />
</td>
    </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2023.02 One paper got accepted by T-CSVT 2023.
</td>
    </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2023.01 One paper got accepted by ICLR 2023.
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2022.03 One paper got accepted by ICME 2022.
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2022.03 One paper got accepted by CVPR 2022.
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2021.03 One paper got accepted by CVPR 2021.
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2020.12 One paper got accepted by AAAI 2021.
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
2020.07 One paper got accepted by NeurIPS 2020.
</td>
 </tr>
<tr>
     <td style="width: 100%; text-align: left;border-color: transparent;"><p><h2>Publications</h2></p>
<hr />
</td>
    </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://arxiv.org/abs/2210.12755"  style="text-decoration:none;" ><b>LCPFormer: Towards Effective 3D Point Cloud Analysis via Local Context Propagation in Transformers</b></a><br>
Zhuoxu Huang, Zhiyou Zhao, <b>Banghuai Li</b>, Jungong Han<br>
<i>IEEE Transactions on Circuits and Systems for Video Technology (<b>T-CSVT</b>)</i>, 2023
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://openreview.net/pdf?id=g1GnnCI1OrC"  style="text-decoration:none;" ><b>E-CRF: Embedded Conditional Random Field for Boundary-caused Class Weights Confusion in Semantic Segmentation</b></a><br>
Jie Zhu, Huabin Huang, <b>Banghuai Li</b>, Leye Wang<br>
<i>International Conference on Learning Representations (<b>ICLR</b>)</i>, 2023
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://openaccess.thecvf.com/content/CVPR2022/html/Li_Adaptive_Hierarchical_Representation_Learning_for_Long-Tailed_Object_Detection_CVPR_2022_paper.html"  style="text-decoration:none;" ><b>Adaptive Hierarchical Representation Learning for Long-Tailed Object Detection</b></a><br>
<b>Banghuai Li</b><br>
<i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) </i>, 2022
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://ieeexplore.ieee.org/document/9859617/"  style="text-decoration:none;" ><b>FBNet: Feature Balance Network for Urban-Scene Segmentation</b></a><br>
Lei Gan, Huabin Huang, <b>Banghuai Li</b>, Ye Yuan<br>
<i> IEEE International Conference on Multimedia and Expo (<b>ICME</b>) </i>, 2022
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.pdf"  style="text-decoration:none;" ><b>FSCE: Few-shot Object Detection via Contrastive Proposal Encoding</b></a><br>
Bo Sun, Shengcai Cai, <b>Banghuai Li</b>, Ye Yuan, Chi Zhang<br>
<i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) </i>, 2021
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://ojs.aaai.org/index.php/AAAI/article/download/16418/16225"  style="text-decoration:none;" ><b>AnchorFace: An Anchor-based Facial Landmark Detector Across Large Poses</b></a><br>
Zixuan Xu, <b>Banghuai Li</b>, Miao Geng, Ye Yuan<br>
<i>AAAI Conference on Artificial Intelligence (<b>AAAI</b>) </i>, 2021
</td>
 </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
<a href="https://proceedings.neurips.cc/paper/2020/file/e6b4b2a746ed40e1af829d1fa82daa10-Paper.pdf"  style="text-decoration:none;" ><b>Beta R-CNN: Looking into Pedestrian Detection from Another Perspective</b></a><br>
Zixuan Xu, <b>Banghuai Li</b>, Ye Yuan, Anhong Dang<br>
<i>Advances in Neural Information Processing Systems (<b>NeurIPS</b>) </i>, 2020
</td>
 </tr>
<tr>
     <td style="width: 100%; text-align: left;border-color: transparent;"><p><h2>Academic Service</h2></p>
<hr />
</td>
    </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
Conference Reviewer for CVPR 2023, CVPR 2022, ICCV 2023, ECCV 2022 <br>
Journal Reviewer for TIP
</td>
 </tr>
<tr>
     <td style="width: 100%; text-align: left;border-color: transparent;"><p><h2>Honours and Awards</h2></p>
<hr />
</td>
    </tr>
<tr>
     <td style="width: 100%;  text-align: left;border-color: transparent;">
Rank 3 in <i>Urban3D: Urban-Scale Point Clouds Understanding Challenge in ICCV 2021</i><br>
Second Prize in <i>The 2nd Next Generation Internet Technology Innovation Competition Final</i><br>
Excellent Graduate of Peking University 

</td>
 </tr>
   </tbody>
  </table>
  <grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>
  <div data-row="0" role="presentation" class="ephox-snooker-resizer-rows ephox-snooker-resizer-bar" style="position: absolute; left: 16px; top: 276.383px; height: 7px; width: 954px;"></div>
  <div data-column="0" role="presentation" class="ephox-snooker-resizer-cols ephox-snooker-resizer-bar" style="position: absolute; left: 489.5px; top: 16px; height: 264.383px; width: 7px;"></div>
  <div data-column="1" role="presentation" class="ephox-snooker-resizer-cols ephox-snooker-resizer-bar" style="position: absolute; left: 966.5px; top: 16px; height: 264.383px; width: 7px;"></div>
 </body>
</html>
